{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "__file__ = \"run_fulll.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/rhome/vgaur/miniconda3/envs/graph-weather/lib/python3.10/site-packages/torch_geometric/typing.py:18: UserWarning: An issue occurred while importing 'pyg-lib'. Disabling its usage. Stacktrace: /lib64/libm.so.6: version `GLIBC_2.29' not found (required by /nas/rhome/vgaur/miniconda3/envs/graph-weather/lib/python3.10/site-packages/libpyg.so)\n",
      "  warnings.warn(f\"An issue occurred while importing 'pyg-lib'. \"\n",
      "/rhome/vgaur/miniconda3/envs/graph-weather/lib/python3.10/site-packages/torch_geometric/typing.py:42: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: /lib64/libm.so.6: version `GLIBC_2.29' not found (required by /nas/rhome/vgaur/miniconda3/envs/graph-weather/lib/python3.10/site-packages/torch_sparse/_metis_cuda.so)\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done Setup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([249098, 65])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                     \r"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[1, 361, 576, 65]' is invalid for input of size 16191370",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/rhome/vgaur/graph_weather_merra/train/run_full_dsig.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bdsig1_vishal/rhome/vgaur/graph_weather_merra/train/run_full_dsig.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=134'>135</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bdsig1_vishal/rhome/vgaur/graph_weather_merra/train/run_full_dsig.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=136'>137</a>\u001b[0m \u001b[39m# forward + backward + optimize\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2Bdsig1_vishal/rhome/vgaur/graph_weather_merra/train/run_full_dsig.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=137'>138</a>\u001b[0m outputs \u001b[39m=\u001b[39m model(inputs)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bdsig1_vishal/rhome/vgaur/graph_weather_merra/train/run_full_dsig.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=139'>140</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bdsig1_vishal/rhome/vgaur/graph_weather_merra/train/run_full_dsig.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=140'>141</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/miniconda3/envs/graph-weather/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/graph-weather/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/nas/rhome/vgaur/graph_weather_merra/train/../graph_weather/models/forecast.py:114\u001b[0m, in \u001b[0;36mGraphWeatherForecaster.forward\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, features: torch\u001b[39m.\u001b[39mTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[1;32m    105\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \u001b[39m    Compute the new state of the forecast\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m        The next state in the forecast\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 114\u001b[0m     x, edge_idx, edge_attr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(features)\n\u001b[1;32m    115\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocessor(x, edge_idx, edge_attr)\n\u001b[1;32m    116\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoder(x, features[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, : \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeature_dim])\n",
      "File \u001b[0;32m~/miniconda3/envs/graph-weather/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/graph-weather/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/nas/rhome/vgaur/graph_weather_merra/train/../graph_weather/models/layers/encoder.py:171\u001b[0m, in \u001b[0;36mEncoder.forward\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[39m# Cat with the h3 nodes to have correct amount of nodes, and in right order\u001b[39;00m\n\u001b[1;32m    170\u001b[0m features \u001b[39m=\u001b[39m einops\u001b[39m.\u001b[39mrearrange(features, \u001b[39m\"\u001b[39m\u001b[39mb n f -> (b n) f\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 171\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnode_encoder(features)  \u001b[39m# Encode to 256 from 78\u001b[39;00m\n\u001b[1;32m    172\u001b[0m edge_attr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39medge_encoder(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39medge_attr)  \u001b[39m# Update attributes based on distance\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \u001b[39m# Copy attributes batch times\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/graph-weather/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/graph-weather/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/nas/rhome/vgaur/graph_weather_merra/train/../graph_weather/models/layers/graph_net_block.py:79\u001b[0m, in \u001b[0;36mMLP.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     \u001b[39mprint\u001b[39m(x\u001b[39m.\u001b[39mshape)\n\u001b[0;32m---> 79\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel(x\u001b[39m.\u001b[39;49mreshape(\u001b[39m1\u001b[39;49m, \u001b[39m361\u001b[39;49m, \u001b[39m576\u001b[39;49m, \u001b[39m65\u001b[39;49m))\n\u001b[1;32m     80\u001b[0m     \u001b[39mprint\u001b[39m(x\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     81\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[1, 361, 576, 65]' is invalid for input of size 16191370"
     ]
    }
   ],
   "source": [
    "\"\"\"Training script for training the weather forecasting model\"\"\"\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.dirname(os.path.realpath(__file__)) + \"/../\")\n",
    "\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import xarray as xr\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "from graph_weather import GraphWeatherForecaster\n",
    "from graph_weather.data import const\n",
    "from graph_weather.models.losses import NormalizedMSELoss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class XrDataset(Dataset):\n",
    "    def __init__(self, file_name):\n",
    "        super().__init__()\n",
    "\n",
    "        self.data = xr.open_dataset(file_name, engine=\"netcdf4\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data.time) - 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # start_idx = np.random.randint(0, len(self.data.time) - 1)\n",
    "        data = self.data.isel(time=slice(idx, idx + 2))\n",
    "        start = data.isel(time=0)\n",
    "        end = data.isel(time=1)\n",
    "\n",
    "        # if inter_data is not None and start != inter_data:\n",
    "        #     start = inter_data\n",
    "        #     end = data.isel(time=0)\n",
    "        # elif start == inter_data:\n",
    "        #     start = data.isel(time = 0)\n",
    "        #     end = data.isel(time = 1)\n",
    "        # else:\n",
    "        #     start = data.isel(time=0)\n",
    "        #     try:\n",
    "        #         end = data.isel(time=1)\n",
    "        #     except IndexError:\n",
    "        #         inter_data = data.isel(time=0)\n",
    "\n",
    "        # Stack the data into a large data cube\n",
    "        input_data = np.stack(\n",
    "            [\n",
    "                (start[f\"{var}\"].values - const.FORECAST_MEANS[f\"{var}\"])\n",
    "                / (const.FORECAST_STD[f\"{var}\"] + 0.0001)\n",
    "                for var in start.data_vars\n",
    "            ],\n",
    "        )\n",
    "        # input_data = np.stack(\n",
    "        #     [(start[f\"{var}\"].values) for var in start.data_vars], axis=-1\n",
    "        # )\n",
    "        input_data = np.nan_to_num(input_data)\n",
    "\n",
    "        assert not np.isnan(input_data).any()\n",
    "        output_data = np.stack(\n",
    "            [\n",
    "                (end[f\"{var}\"].values - const.FORECAST_MEANS[f\"{var}\"])\n",
    "                / (const.FORECAST_STD[f\"{var}\"] + 0.0001)\n",
    "                for var in end.data_vars\n",
    "            ]\n",
    "        )\n",
    "        # output_data = np.stack(\n",
    "        #     [(end[f\"{var}\"].values) for var in end.data_vars], axis=-1\n",
    "        # )\n",
    "        output_data = np.nan_to_num(output_data)\n",
    "        assert not np.isnan(output_data).any()\n",
    "        transform = transforms.Compose([transforms.ToTensor()])\n",
    "        # Normalize now\n",
    "        return (\n",
    "            transform(input_data)\n",
    "            .transpose(0, 2)\n",
    "            .transpose(1, 2)\n",
    "            .reshape(-1, input_data.shape[0]),\n",
    "            transform(input_data)\n",
    "            .transpose(0, 2)\n",
    "            .transpose(1, 2)\n",
    "            .reshape(-1, input_data.shape[0]),\n",
    "        )\n",
    "\n",
    "\n",
    "data = xr.open_dataset(\n",
    "    \"../graph_weather/data/MERRA2_400.inst3_3d_asm_Nv.20230701_merged.nc\",\n",
    "    engine=\"netcdf4\",\n",
    ")\n",
    "# print(data)\n",
    "# print(\"Done coarsening\")\n",
    "# meshgrid takes in the lat and lon values, creates the arrays of every single latitude with the length of every single longitude, np.array reshapes it to get a matrix\n",
    "# which contains the lat lon co-related values, eg. 90*180, 90*179.375 etc.\n",
    "lat_lons = np.array(np.meshgrid(data.lat.values, data.lon.values)).T.reshape(-1, 2)\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "# device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "# Get the variance of the variables\n",
    "feature_variances = []\n",
    "for var in data.data_vars:\n",
    "    feature_variances.append(const.FORECAST_DIFF_STD[var] ** 2)\n",
    "criterion = NormalizedMSELoss(\n",
    "    lat_lons=lat_lons, feature_variance=feature_variances, device=device\n",
    ").to(device)\n",
    "means = []\n",
    "# dataset = DataLoader(XrDataset(), batch_size=1)\n",
    "# files_dataloader = DataLoader(FileDataset(\"graph_weather/data/train_data\"), batch_size = 1)\n",
    "model = GraphWeatherForecaster(lat_lons, feature_dim=65, num_blocks=6).to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.000001)\n",
    "print(\"Done Setup\")\n",
    "import time\n",
    "\n",
    "train_files = glob(\"../graph_weather/data/train_data/*.nc\", recursive=True)\n",
    "val_files = glob(\"../graph_weather/data/val_data/*.nc\", recursive=True)\n",
    "running_loss, running_val_loss = [], []\n",
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "    model.train()\n",
    "    start = time.time()\n",
    "    inter_data = None\n",
    "    running_loss_files = []\n",
    "    running_val_loss_files = []\n",
    "    for name in train_files:\n",
    "        dataset = DataLoader(XrDataset(name), batch_size=1)\n",
    "\n",
    "        # print(f\"Start Epoch: {epoch+1}\")\n",
    "        for i, data in tqdm(enumerate(dataset), total=len(dataset), leave=False):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss_files.append(loss.item())\n",
    "        print(f\"{epoch + 1} training_loss: {np.mean(running_loss_files)}\")\n",
    "\n",
    "    model.eval()\n",
    "    for name in val_files:\n",
    "        dataset = DataLoader(XrDataset(name), batch_size=1)\n",
    "\n",
    "        # print(f\"Start Epoch: {epoch+1}\")\n",
    "        for i, data in tqdm(enumerate(dataset), total=len(dataset), leave=False):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            val_loss = criterion(outputs, labels)\n",
    "\n",
    "            # print statistics\n",
    "            running_val_loss_files.append(val_loss.item())\n",
    "            # print(f\"[{epoch + 1}, {i + 1:5d}] loss: {running_loss / (i + 1):.3f}\")\n",
    "        print(f\"{epoch + 1} validation_loss: {np.mean(running_val_loss_files)}\")\n",
    "\n",
    "    running_loss.append(np.mean(running_loss_files))\n",
    "    running_val_loss.append(np.mean(running_val_loss_files))\n",
    "end = time.time()\n",
    "print(f\"Time: {end - start} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(running_loss)\n",
    "plt.plot(running_val_loss)\n",
    "plt.title(\"model accuracy\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend([\"train\", \"val\"], loc=\"upper left\")\n",
    "# plt.savefig(\"openweather_20epochs_merra_batch_2.png\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = glob(\"../graph_weather/data/test_data/*.nc\", recursive=True)\n",
    "test_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DataLoader(XrDataset(test_dir[0]), batch_size= 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = iter(dataset)\n",
    "inputs, labels = next(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, labels = inputs.to(device), labels.to(device)\n",
    "outputs_test = model(inputs)\n",
    "diff_test = labels - outputs_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "fig1, ax1 = plt.subplots(2, 2, figsize=(12, 12))\n",
    "sns.heatmap(torch.reshape(inputs, (1, 361, 576, 65))[0, :, :, 27], cbar = True, cmap = 'Blues', ax = ax1[0][0])\n",
    "ax1[0][0].set_title(\"Test Input Image\")\n",
    "\n",
    "sns.heatmap(torch.reshape(labels, (1, 361, 576, 65))[0, :, :, 27], cbar = True, cmap = 'Blues', ax = ax1[0][1])\n",
    "ax1[0][1].set_title(\"Test Output Image\")\n",
    "\n",
    "sns.heatmap(torch.reshape(outputs_test, (1, 361, 576, 65)).detach().numpy()[0, :, :, 27], cmap = 'Blues', cbar= True, ax = ax1[1][0])\n",
    "ax1[1][0].set_title(\"Predicted Image\")\n",
    "\n",
    "sns.heatmap(torch.reshape(diff_test, (1, 361, 576, 65)).detach().numpy()[0, :, :, 27], cmap = 'Blues', cbar = True, ax = ax1[1][1])\n",
    "ax1[1][1].set_title(\"Difference in actual output and prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1, ax1 = plt.subplots(2, 2, figsize=(12, 12))\n",
    "sns.heatmap(torch.reshape(inputs, (1, 361, 576, 65))[0, :, :, 64], cbar = True, cmap = 'Blues', ax = ax1[0][0])\n",
    "ax1[0][0].set_title(\"Test Input Image\")\n",
    "\n",
    "sns.heatmap(torch.reshape(labels, (1, 361, 576, 65))[0, :, :, 64], cbar = True, cmap = 'Blues', ax = ax1[0][1])\n",
    "ax1[0][1].set_title(\"Test Output Image\")\n",
    "\n",
    "sns.heatmap(torch.reshape(outputs_test, (1, 361, 576, 65)).detach().numpy()[0, :, :, 64], cmap = 'Blues', cbar= True, ax = ax1[1][0])\n",
    "ax1[1][0].set_title(\"Predicted Image\")\n",
    "\n",
    "sns.heatmap(torch.reshape(diff_test, (1, 361, 576, 65)).detach().numpy()[0, :, :, 64], cmap = 'Blues', cbar = True, ax = ax1[1][1])\n",
    "ax1[1][1].set_title(\"Difference in actual output and prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in glob(\"graph_weather/data/test_data/*.nc\", recursive=True):\n",
    "    dataset = DataLoader(XrDataset(name), batch_size=1)\n",
    "    fig1, ax1 = plt.subplots(2, 2, figsize=(12, 12))\n",
    "    fig1.suptitle(\"Test Image\")\n",
    "    for i, data in tqdm(enumerate(dataset), total=len(dataset), leave=False):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs_test, labels = data[0].to(device), data[1].to(device)\n",
    "        ax1[0][0].imshow(torch.reshape(inputs_test, (1, 361, 576, 65))[0, :, :, 27])\n",
    "        ax1[0][0].set_title(\"Test Input Image\")\n",
    "\n",
    "        ax1[0][1].imshow(torch.reshape(labels, (1, 361, 576, 65))[0, :, :, 27])\n",
    "        ax1[0][1].set_title(\"Test Output Image\")\n",
    "        # zero the parameter gradients\n",
    "        # forward + backward + optimize\n",
    "        outputs_test = model(inputs_test)\n",
    "        ax1[1][0].imshow(\n",
    "            torch.reshape(outputs_test, (1, 361, 576, 65)).detach().numpy()[0, :, :, 27]\n",
    "        )\n",
    "        ax1[1][0].set_title(\"Predicted Image\")\n",
    "\n",
    "        diff_test = labels - outputs_test\n",
    "\n",
    "        ax1[1][1].imshow(\n",
    "            torch.reshape(diff_test, (1, 361, 576, 65)).detach().numpy()[0, :, :, 27]\n",
    "        )\n",
    "        ax1[1][1].set_title(\"Difference in actual output and prediction\")\n",
    "\n",
    "        plt.savefig(f\"results_{name.split('/')[-1][:-3]}_{i}_prediction.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph-weather",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
